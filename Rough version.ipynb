{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM STATEMENT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Many UFO's are visible on a video frame with different numbers ranging from 0 - 9 written on them. The task is to find the location of those UFO's on each frame, sort them from top to bottom by their position and return numbers written on them. \n",
    "\n",
    "\n",
    "\n",
    "![title](frame.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this detection technique is to determine where objects are located in a given image called as object localisation and which category each object belongs to, that is called as object classification.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 21.1.1 from /Applications/anaconda3/lib/python3.7/site-packages/pip (python 3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Applications/anaconda3/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Applications/anaconda3/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /Applications/anaconda3/lib/python3.7/site-packages (4.4.0.46)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Applications/anaconda3/lib/python3.7/site-packages (from opencv-python) (1.19.5)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Applications/anaconda3/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Applications/anaconda3/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Applications/anaconda3/lib/python3.7/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read the file using OpenCV and create an instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img_file = 'frame.jpg'\n",
    "\n",
    "# create an opencv image\n",
    "img = cv2.imread(img_file)\n",
    "\n",
    "# convert the image to gray scale format\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# applying canny edge detection\n",
    "edged = cv2.Canny(img, 10, 250)\n",
    "\n",
    "#finding contours\n",
    "(cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "def get_contour_precedence(contour, cols):\n",
    "    tolerance_factor = 10\n",
    "    origin = cv2.boundingRect(contour)\n",
    "    return ((origin[1] // tolerance_factor) * tolerance_factor) * cols + origin[0]\n",
    "\n",
    "cnts.sort(key=lambda x:get_contour_precedence(x, img.shape[1]))\n",
    "\n",
    "# For debugging purposes.\n",
    "#for i in range(len(cnts)):\n",
    "    #img = cv2.putText(img, str(i), cv2.boundingRect(cnts[i])[:2], cv2.FONT_HERSHEY_COMPLEX, 1, [125])\n",
    "    \n",
    "\n",
    "idx = 0\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    if w>50 and h>50:\n",
    "        idx+=1\n",
    "        new_img=img[y:y+h,x:x+w]\n",
    "        #cropping images\n",
    "        cv2.imwrite(\"cropped/\"+str(idx) + '.png', new_img)\n",
    "#cv2.imshow(\"Original Image\",image)\n",
    "#cv2.imshow(\"Canny Edge\",edged)\n",
    "#cv2.waitKey(0)\n",
    "print('>> Objects Cropped Successfully!')\n",
    "print(\">> Check out 'cropped' Directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 900, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from above we can infer that :-\n",
    "\n",
    "A. img is the digital representation of image interms of pixel intensities ranging from 0-255\n",
    "B. The resolution of the image. is 506X900 , where each pixel value is of depth 3 containing values for 3 primary\n",
    "colours Red,Blue,Green (RBG).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "APPROACH 1 -\n",
    "\n",
    "HAAR CASCADE CLASSIFIERS are an effective way for object detection.Haar Cascade is a machine learning-based \n",
    "approach where a lot of positive and negative images are used to train the classifier.\n",
    "\n",
    "1. Positive images – These images contain the images which we want our classifier to identify.\n",
    "2. Negative Images – Images of everything else, which do not contain the object we want to detect.\n",
    "\n",
    "In total we will be require 10 HAAR cascade classifiers that will identify the features of the objects and therefore\n",
    "the object types ranging from 0-9.\n",
    "\n",
    "Below are our custom made HAAR CASCADE CLASSIFIERS.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "APPROACH 2 FOR OBJECT DETECTION -\n",
    "\n",
    "Knowing where an object is in an image is called localization in computer vision. \n",
    "Using contour detection, we can detect the borders of objects, and therefore, localize them easily.\n",
    "\n",
    "we are going to do contours and contour detection using OpenCV(coding in both Python).\n",
    "\n",
    "1.OpenCV makes it really easy for finding, and drawing contours in images. It provides two simple \n",
    "functions to do so: findContours(), and drawContours().\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image to gray scale format\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143, 142, 144, ..., 214, 214, 215],\n",
       "       [140, 140, 142, ..., 213, 213, 214],\n",
       "       [139, 139, 141, ..., 213, 213, 214],\n",
       "       ...,\n",
       "       [105, 102, 105, ..., 115, 116, 118],\n",
       "       [104, 102, 105, ..., 116, 116, 118],\n",
       "       [109, 106, 109, ..., 118, 119, 121]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "we are using OpenCV’s cvtColor() function to convert the original RGB image to a grayscale image. this will help \n",
    "to apply binary thresholding and in obtaining much better results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply binary thresholding\n",
    "\n",
    "ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# visualize the binary image\n",
    "\n",
    "cv2.imshow('Binary image', thresh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imwrite('image_thres1.jpg', thresh)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We are using the threshold() function to apply binary thresholding to the image. \n",
    "Any pixel with a value greater than 150 will be updated  to a value of 255, that is, \n",
    "completely white. And, all the other pixels in the resulting image will be 0, that is, black. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us find and draw the contours using the CHAIN_APPROX_NONE method. \n",
    "\n",
    "contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# draw contours on the original image\n",
    "\n",
    "image_copy = image.copy()\n",
    "\n",
    "cv2.drawContours(image=image_copy, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "# see the results\n",
    "\n",
    "cv2.imshow('None approximation', image_copy)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imwrite('contours_none_image1.jpg', image_copy)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to actually visualize the effect of `CHAIN_APPROX_SIMPLE`, we need a proper image\n",
    "\n",
    "image1 = cv2.imread('frame.jpg')\n",
    "\n",
    "img_gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh1 = cv2.threshold(img_gray1, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "contours2, hierarchy2 = cv2.findContours(thresh1, cv2.RETR_TREE,\n",
    "\n",
    "                                               cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "image_copy2 = image1.copy()\n",
    "\n",
    "cv2.drawContours(image_copy2, contours2, -1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('SIMPLE Approximation contours', image_copy2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "image_copy3 = image1.copy()\n",
    "\n",
    "for i, contour in enumerate(contours2): # loop over one contour area\n",
    "    for j, contour_point in enumerate(contour): # loop over the points\n",
    "\n",
    "       # draw a circle on the current contour coordinate\n",
    "\n",
    "       cv2.circle(image_copy3, ((contour_point[0][0], contour_point[0][1])), 2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "# see the results\n",
    "\n",
    "cv2.imshow('CHAIN_APPROX_SIMPLE Point only', image_copy3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imwrite('contour_point_simple.jpg', image_copy3)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying canny edge detection\n",
    "edged = cv2.Canny(img, 10, 250)\n",
    "\n",
    "#finding contours\n",
    "(cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 77, 141, 172],\n",
       "        [ 76, 140, 171],\n",
       "        [ 77, 141, 175],\n",
       "        ...,\n",
       "        [180, 213, 229],\n",
       "        [180, 213, 229],\n",
       "        [181, 214, 230]],\n",
       "\n",
       "       [[ 74, 138, 169],\n",
       "        [ 74, 138, 169],\n",
       "        [ 75, 139, 173],\n",
       "        ...,\n",
       "        [179, 212, 228],\n",
       "        [179, 212, 228],\n",
       "        [180, 213, 229]],\n",
       "\n",
       "       [[ 73, 137, 168],\n",
       "        [ 73, 137, 168],\n",
       "        [ 74, 138, 172],\n",
       "        ...,\n",
       "        [179, 212, 228],\n",
       "        [179, 212, 228],\n",
       "        [180, 213, 229]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 41, 115, 109],\n",
       "        [ 38, 112, 106],\n",
       "        [ 41, 115, 109],\n",
       "        ...,\n",
       "        [ 49, 125, 121],\n",
       "        [ 50, 126, 122],\n",
       "        [ 52, 128, 124]],\n",
       "\n",
       "       [[ 40, 114, 108],\n",
       "        [ 38, 112, 106],\n",
       "        [ 41, 115, 109],\n",
       "        ...,\n",
       "        [ 50, 126, 122],\n",
       "        [ 50, 126, 122],\n",
       "        [ 52, 128, 124]],\n",
       "\n",
       "       [[ 45, 119, 113],\n",
       "        [ 42, 116, 110],\n",
       "        [ 45, 119, 113],\n",
       "        ...,\n",
       "        [ 52, 128, 124],\n",
       "        [ 53, 129, 125],\n",
       "        [ 55, 131, 127]]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_precedence(contour, cols):\n",
    "    tolerance_factor = 10\n",
    "    origin = cv2.boundingRect(contour)\n",
    "    return ((origin[1] // tolerance_factor) * tolerance_factor) * cols + origin[0]\n",
    "\n",
    "cnts.sort(key=lambda x:get_contour_precedence(x, img.shape[1]))\n",
    "\n",
    "# For debugging purposes.\n",
    "#for i in range(len(cnts)):\n",
    "    #img = cv2.putText(img, str(i), cv2.boundingRect(cnts[i])[:2], cv2.FONT_HERSHEY_COMPLEX, 1, [125])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0, 255, 255],\n",
       "        [  0, 255, 255],\n",
       "        [  0, 255, 255],\n",
       "        ...,\n",
       "        [  0, 255, 255],\n",
       "        [  0, 255, 255],\n",
       "        [  0, 255, 255]],\n",
       "\n",
       "       [[  0, 255, 255],\n",
       "        [  0, 255, 255],\n",
       "        [  0, 255, 255],\n",
       "        ...,\n",
       "        [  0, 255, 255],\n",
       "        [  0, 255, 255],\n",
       "        [  0, 255, 255]],\n",
       "\n",
       "       [[  0, 255, 255],\n",
       "        [  0, 255, 255],\n",
       "        [  0, 255, 255],\n",
       "        ...,\n",
       "        [  0, 255, 255],\n",
       "        [  0, 255, 255],\n",
       "        [  0, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"cropped/\"+'contours_sort.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Objects Cropped Successfully!\n",
      ">> Check out 'cropped' Directory\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    if w>50 and h>50:\n",
    "        idx+=1\n",
    "        new_img=img[y:y+h,x:x+w]\n",
    "        #cropping images\n",
    "        cv2.imwrite(\"cropped/\"+str(idx) + '.png', new_img)\n",
    "#cv2.imshow(\"Original Image\",image)\n",
    "#cv2.imshow(\"Canny Edge\",edged)\n",
    "#cv2.waitKey(0)\n",
    "print('>> Objects Cropped Successfully!')\n",
    "print(\">> Check out 'cropped' Directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "10\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "img_1 = cv2.imread('2.png', 0)\n",
    "img_2 = cv2.imread('img1.jpg', 0)\n",
    "\n",
    "ret, thresh = cv2.threshold(img_1, 127, 255, 0)\n",
    "ret, thresh2 = cv2.threshold(img_2, 127, 255, 0)\n",
    "contours1, hierarchy = cv2.findContours(thresh, 2, 1)\n",
    "print(len(contours1))\n",
    "cnt1 = contours1[1]\n",
    "contours2, hierarchy = cv2.findContours(thresh2, 2, 1)\n",
    "print(len(contours2))\n",
    "cnt2 = contours2[1]\n",
    "ret = cv2.matchShapes(cnt1, cnt2, 1, 0.0)\n",
    "\n",
    "print(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread('frame.jpg')\n",
    "original_copy = original_image.copy()\n",
    "image = cv2.imread('frame.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "canny = cv2.Canny(gray, 130, 255, 1)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "\n",
    "cnts = cv2.findContours(dilate, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.01 * peri, True)\n",
    "    x,y,w,h = cv2.boundingRect(approx)\n",
    "    aspect_ratio = w / float(h)\n",
    "\n",
    "    if (aspect_ratio >= 0.8 and aspect_ratio <= 1.6):\n",
    "        ROI = original_copy[y:y+h, x:x+w]\n",
    "        cv2.rectangle(original_image,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "\n",
    "cv2.imshow('canny', canny)\n",
    "cv2.imshow('dilate', dilate)\n",
    "cv2.imshow('original image', original_image)\n",
    "cv2.imshow('ROI', ROI)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
